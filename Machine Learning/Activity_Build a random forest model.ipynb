{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "700acefd-8120-42a9-a650-c610467e2a4c"
   },
   "source": [
    "# Activity: Build a random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "167f3ab7"
   },
   "source": [
    "## **Introduction**\n",
    "\n",
    "\n",
    "As you're learning, random forests are popular statistical learning algorithms. Some of their primary benefits include reducing variance, bias, and the chance of overfitting.\n",
    "\n",
    "This activity is a continuation of the project you began modeling with decision trees for an airline. Here, you will train, tune, and evaluate a random forest model using data from spreadsheet of survey responses from 129,880 customers. It includes data points such as class, flight distance, and inflight entertainment. Your random forest model will be used to predict whether a customer will be satisfied with their flight experience.\n",
    "\n",
    "**Note:** Because this lab uses a real dataset, this notebook first requires exploratory data analysis, data cleaning, and other manipulations to prepare it for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b42252b9-b980-4ee0-8cfd-82f4239b6d1a"
   },
   "source": [
    "## **Step 1: Imports** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwVaqXCywHpx"
   },
   "source": [
    "Import relevant Python libraries and modules, including `numpy` and `pandas`libraries for data processing; the `pickle` package to save the model; and the `sklearn` library, containing:\n",
    "- The module `ensemble`, which has the function `RandomForestClassifier`\n",
    "- The module `model_selection`, which has the functions `train_test_split`, `PredefinedSplit`, and `GridSearchCV` \n",
    "- The module `metrics`, which has the functions `f1_score`, `precision_score`, `recall_score`, and `accuracy_score`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebc64d8b"
   },
   "outputs": [],
   "source": [
    "# Import `numpy`, `pandas`, `pickle`, and `sklearn`.\n",
    "# Import the relevant functions from `sklearn.ensemble`, `sklearn.model_selection`, and `sklearn.metrics`.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6msd7EKhg3X"
   },
   "source": [
    "Next, load the dataset into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvRXUsRChmtg"
   },
   "outputs": [],
   "source": [
    "# Load data.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRC0c_6M3ruN"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `read_csv()` function from the `pandas` library can be helpful here.\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUvhnNqmvnXP"
   },
   "source": [
    "Now, you're ready to begin cleaning your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ac7573d"
   },
   "source": [
    "## **Step 2: Data cleaning** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "555658e4"
   },
   "source": [
    "To get a sense of the data, display the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cda01022"
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7IVcXx_3fFq"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `head()` function from the `pandas` library can be helpful here.\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XnaSp-1bco5"
   },
   "source": [
    "Now, display the variable names and their data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjTctqf_cZZk"
   },
   "outputs": [],
   "source": [
    "# Display variable names and types.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyjsCPSFdWSi"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "DataFrames have an attribute that outputs variable names and data types in one result.\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZWcyh0ia_mn"
   },
   "source": [
    "**Question:** What do you observe about the differences in data types among the variables included in the data?\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDHCzUpwBqTD"
   },
   "source": [
    "Next, to understand the size of the dataset, identify the number of rows and the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-s0dOOgBr-1"
   },
   "outputs": [],
   "source": [
    "# Identify the number of rows and the number of columns.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7phg3U50drdh"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "There is a method in the `pandas` library that outputs the number of rows and the number of columns in one result.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ada5a098-e0d2-4a59-9ac5-132d8ea1eb3c",
    "tags": []
   },
   "source": [
    "Now, check for missing values in the rows of the data. Start with .isna() to get Booleans indicating whether each value in the data is missing. Then, use .any(axis=1) to get Booleans indicating whether there are any missing values along the columns in each row. Finally, use .sum() to get the number of rows that contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "db9be321-d578-4252-833c-a2dfd0e2e937"
   },
   "outputs": [],
   "source": [
    "# Get Booleans to find missing values in data.\n",
    "# Get Booleans to find missing values along columns.\n",
    "# Get the number of rows that contain missing values.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74e5308a-7607-4277-a508-d0efa10d9116"
   },
   "source": [
    "**Question:** How many rows of data are missing values?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb005a73-4621-45b9-8114-30472ce20327"
   },
   "source": [
    "Drop the rows with missing values. This is an important step in data cleaning, as it makes the data more useful for analysis and regression. Then, save the resulting pandas DataFrame in a variable named `air_data_subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cee438e-8b1f-4855-855e-3723d1958b69"
   },
   "outputs": [],
   "source": [
    "# Drop missing values.\n",
    "# Save the DataFrame in variable `air_data_subset`.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AHDkLF5pnao"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `dropna()` function is helpful here.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The axis parameter passed in to this function should be set to 0 (if you want to drop rows containing missing values) or 1 (if you want to drop columns containing missing values).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0021b18e-4c93-4628-8d0d-2c55a98cc691"
   },
   "source": [
    "Next, display the first 10 rows to examine the data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad471526-eb38-4cc3-afa7-f9542439ea35"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c74ad00-3eaf-4868-b3a9-3aa87a5bc0d3",
    "tags": []
   },
   "source": [
    "Confirm that it does not contain any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f22e303c-2c42-4227-9083-447839e2b300"
   },
   "outputs": [],
   "source": [
    "# Count of missing values.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0Y9g4C17al8"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can use the `.ina().sum()` to get the number of missing values for each variable.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23bbe395"
   },
   "source": [
    "Next, convert the categorical features to indicator (one-hot encoded) features. \n",
    "\n",
    "**Note:** The `drop_first` argument can be kept as default (`False`) during one-hot encoding for random forest models, so it does not need to be specified. Also, the target variable, `satisfaction`, does not need to be encoded and will be extracted in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03d00d56"
   },
   "outputs": [],
   "source": [
    "# Convert categorical features to one-hot encoded features.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9d3a8d5"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can use the `pd.get_dummies()` function to convert categorical variables to one-hot encoded variables.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fY6JM-6zfNLK"
   },
   "source": [
    "**Question:** Why is it necessary to convert categorical data into dummy variables?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfe87acc"
   },
   "source": [
    "Next, display the first 10 rows to review the `air_data_subset_dummies`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "139cb903"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXzLIPbYYvud"
   },
   "source": [
    "Then, check the variables of air_data_subset_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1V76nRmZoWN"
   },
   "outputs": [],
   "source": [
    "# Display variables.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJkFXh96gIA2"
   },
   "source": [
    "**Question:** What changes do you observe after converting the string data to dummy variables?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b7f8803-44ee-47cf-b97a-efaf5c0fdd59",
    "tags": []
   },
   "source": [
    "## **Step 3: Model building** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sf5gGBFySHv"
   },
   "source": [
    "The first step to building your model is separating the labels (y) from the features (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80535d2f-8b1a-4715-b07a-f3734d8cc4c5"
   },
   "outputs": [],
   "source": [
    "# Separate the dataset into labels (y) and features (X).\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18fn6lxL8O8Q"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Save the labels (the values in the `satisfaction` column) as `y`.\n",
    "\n",
    "Save the features as `X`. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "To obtain the features, drop the `satisfaction` column from the DataFrame.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49a6c7ae"
   },
   "source": [
    "Once separated, split the data into train, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0de77cb8"
   },
   "outputs": [],
   "source": [
    "# Separate into train, validate, test sets.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16c78c74"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `train_test_split()` function twice to create train/validate/test sets, passing in `random_state` for reproducible results. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Split `X`, `y` to get `X_train`, `X_test`, `y_train`, `y_test`. Set the `test_size` argument to the proportion of data points you want to select for testing. \n",
    "\n",
    "Split `X_train`, `y_train` to get `X_tr`, `X_val`, `y_tr`, `y_val`. Set the `test_size` argument to the proportion of data points you want to select for validation. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59bbd17e-84e5-463c-8806-f2b5286f9ac8",
    "tags": []
   },
   "source": [
    "### Tune the model\n",
    "\n",
    "Now, fit and tune a random forest model with separate validation set. Begin by determining a set of hyperparameters for tuning the model using GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bfdf346"
   },
   "outputs": [],
   "source": [
    "# Determine set of hyperparameters.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMdizCS0rZB4"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Create a dictionary `cv_params` that maps each hyperparameter name to a list of values. The GridSearch you conduct will set the hyperparameter to each possible value, as specified, and determine which value is optimal.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Swkbtmw7tMMv"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The main hyperparameters here include `'n_estimators', 'max_depth', 'min_samples_leaf', 'min_samples_split', 'max_features', and 'max_samples'`. These will be the keys in the dictionary `cv_params`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a list of split indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a58b4d77-6023-428d-89aa-4d2ac52003dc"
   },
   "outputs": [],
   "source": [
    "# Create list of split indices.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USX90GwZt3xU"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use list comprehension, iterating over the indices of `X_train`. The list can consists of 0s to indicate data points that should be treated as validation data and -1s to indicate data points that should be treated as training data.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Use `PredfinedSplit()`, passing in `split_index`, saving the output as `custom_split`. This will serve as a custom split that will identify which data points from the train set should be treated as validation data during GridSearch.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0qvZjujbTKL"
   },
   "outputs": [],
   "source": [
    "# Instantiate model.\n",
    "\n",
    "### YOUR CODE HERE ### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voetM7-QwI5w"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use `RandomForestClassifier()`, specifying the `random_state` argument for reproducible results. This will help you instantiate a random forest model, `rf`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use GridSearchCV to search over the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "228e65c3"
   },
   "outputs": [],
   "source": [
    "# Search over specified parameters.\n",
    "\n",
    "### YOUR CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bppjmuqzwZf3"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use `GridSearchCV()`, passing in `rf` and `cv_params` and specifying `cv` as `custom_split`. Additional arguments that you can specify include: `refit='f1', n_jobs = -1, verbose = 1`. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gw_woSKtfsAk"
   },
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUYHWoZsyJs0"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `fit()` method to train the GridSearchCV model on `X_train` and `y_train`. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Add the magic function `%%time` to keep track of the amount of time it takes to fit the model and display this information once execution has completed. Remember that this code must be the first line in the cell.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, obtain the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c76a0bd9"
   },
   "outputs": [],
   "source": [
    "# Obtain optimal parameters.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "604a475e"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `best_params_` attribute to obtain the optimal values for the hyperparameters from the GridSearchCV model.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70fc3ec6-a89a-4b25-a574-29f9d4325694"
   },
   "source": [
    "## **Step 4: Results and evaluation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXqywQtvyrS1"
   },
   "source": [
    "Use the selected model to predict on your test data. Use the optimal parameters found via GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6b8aa2d-984f-467a-b52a-e7f21d603a8c"
   },
   "outputs": [],
   "source": [
    "# Use optimal parameters on GridSearchCV.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu3sgtdRzmmJ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use `RandomForestClassifier()`, specifying the `random_state` argument for reproducible results and passing in the optimal hyperparameters found in the previous step. To distinguish this from the previous random forest model, consider naming this variable `rf_opt`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, fit the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJ7MkQ3hjh3u"
   },
   "outputs": [],
   "source": [
    "# Fit the optimal model.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAKs_7Ms0HAO"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `fit()` method to train `rf_opt` on `X_train` and `y_train`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predict on the test set using the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cc40ec1-5fa4-4803-9021-abea9699a804"
   },
   "outputs": [],
   "source": [
    "# Predict on test set.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4df36d33"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `predict()` function to make predictions on `X_test` using `rf_opt`. Save the predictions now (for example, as `y_pred`), to use them later for comparing to the true labels. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "153a8200"
   },
   "source": [
    "### Obtain performance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cea208e9"
   },
   "source": [
    "First, get your precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6913aa4b"
   },
   "outputs": [],
   "source": [
    "# Get precision score.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVtVtsLV0ddI"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `precision_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66dda49b"
   },
   "source": [
    "Then, collect the recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd971df6"
   },
   "outputs": [],
   "source": [
    "# Get recall score.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XUaS34s1yH_"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `recall_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea594a68"
   },
   "source": [
    "Next, obtain your accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "011b8b71"
   },
   "outputs": [],
   "source": [
    "# Get accuracy score.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QProyXMS10zG"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `accuracy_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "871ea5cb"
   },
   "source": [
    "Finally, collect your F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "490fcb3e"
   },
   "outputs": [],
   "source": [
    "# Get F1 score.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtBQWSVs13dT"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `f1_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1edc4c95-1cf4-4e05-b2a2-dc18cadb3d63"
   },
   "source": [
    "**Question:** How is the F1-score calculated?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfkbwjlvcX3k"
   },
   "source": [
    "**Question:** What are the pros and cons of performing the model selection using test data instead of a separate validation dataset?\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "510b2158-2813-4600-868e-a909595a2366"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Now that you have results, evaluate the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57771b26"
   },
   "source": [
    "**Question:** What are the four basic parameters for evaluating the performance of a classification model?\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LojJPkIrjNbJ"
   },
   "source": [
    "**Question:**  What do the four scores demonstrate about your model, and how do you calculate them?\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the scores: precision score, recall score, accuracy score, F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUT99rnqOds3"
   },
   "outputs": [],
   "source": [
    "# Precision score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTiaHUVvTiUN"
   },
   "outputs": [],
   "source": [
    "# Recall score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrYHruUdV1Os"
   },
   "outputs": [],
   "source": [
    "# Accuracy score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKGc64U2YbL1"
   },
   "outputs": [],
   "source": [
    "# F1 score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does this model perform based on the four scores?\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaKUSbqDW28K"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Finally, create a table of results that you can use to evaluate the performace of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6L7AgdeldsKZ"
   },
   "outputs": [],
   "source": [
    "# Create table of results.\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqu9L0ip328H"
   },
   "source": [
    "\n",
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Build a table to compare the performance of the models. Create a DataFrame and use the `append()` function to add the results of each model as a new row.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trUO9XEHbXG6"
   },
   "source": [
    "**Question:** How does the random forest model compare to the decision tree model you built in the previous lab?\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okMTunOhpotF"
   },
   "source": [
    "## **Considerations**\n",
    "\n",
    "\n",
    "**What are the key takeaways from this lab? Consider important steps when building a model, most effective approaches and tools, and overall results.**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]\n",
    "\n",
    "\n",
    "**What summary would you provide to stakeholders?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb58bfc4"
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c2abcc0"
   },
   "source": [
    "[Accuracy, Precision, Recall & F1 Score: Interpretation of Performance Measures, Renuka Joshi](https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/)\n",
    "\n",
    "[What is the Difference Between Test and Validation Datasets?,  Jason Brownlee](https://machinelearningmastery.com/difference-test-validation-datasets/)\n",
    "\n",
    "[Decision Trees and Random Forests Neil Liberman](https://towardsdatascience.com/decision-trees-and-random-forests-df0c3123f991)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1ajeXfekjHYYlATQqDdzWb2bjoSQPy9e5",
     "timestamp": 1661470003810
    },
    {
     "file_id": "1sKzoVdsFNq2nBg0uus6LyTzuD2Ktou4t",
     "timestamp": 1661452831142
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
