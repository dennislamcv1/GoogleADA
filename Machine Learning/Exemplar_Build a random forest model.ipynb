{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "700acefd-8120-42a9-a650-c610467e2a4c"
   },
   "source": [
    "# Exemplar: Build a random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "167f3ab7"
   },
   "source": [
    "## **Introduction**\n",
    "\n",
    "\n",
    "As you're learning, random forests are popular statistical learning algorithms. Some of their primary benefits include reducing variance, bias, and the chance of overfitting.\n",
    "\n",
    "This activity is a continuation of the project you began modeling with decision trees for an airline. Here, you will train, tune, and evaluate a random forest model using data from spreadsheet of survey responses from 129,880 customers. It includes data points such as class, flight distance, and inflight entertainment. Your random forest model will be used to predict whether a customer will be satisfied with their flight experience.\n",
    "\n",
    "**Note:** Because this lab uses a real dataset, this notebook first requires exploratory data analysis, data cleaning, and other manipulations to prepare it for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b42252b9-b980-4ee0-8cfd-82f4239b6d1a"
   },
   "source": [
    "## **Step 1: Imports** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwVaqXCywHpx"
   },
   "source": [
    "Import relevant Python libraries and modules, including `numpy` and `pandas`libraries for data processing; the `pickle` package to save the model; and the `sklearn` library, containing:\n",
    "- The module `ensemble`, which has the function `RandomForestClassifier`\n",
    "- The module `model_selection`, which has the functions `train_test_split`, `PredefinedSplit`, and `GridSearchCV` \n",
    "- The module `metrics`, which has the functions `f1_score`, `precision_score`, `recall_score`, and `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebc64d8b"
   },
   "outputs": [],
   "source": [
    "# Import `numpy`, `pandas`, `pickle`, and `sklearn`.\n",
    "# Import the relevant functions from `sklearn.ensemble`, `sklearn.model_selection`, and `sklearn.metrics`.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle as pkl\n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6msd7EKhg3X"
   },
   "source": [
    "Next, load the dataset into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvRXUsRChmtg"
   },
   "outputs": [],
   "source": [
    "# Load data.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data = pd.read_csv(\"Invistico_Airline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRC0c_6M3ruN"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `read_csv()` function from the `pandas` library can be helpful here.\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUvhnNqmvnXP"
   },
   "source": [
    "Now, you're ready to begin cleaning your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ac7573d"
   },
   "source": [
    "## **Step 2: Data cleaning** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "555658e4"
   },
   "source": [
    "To get a sense of the data, display the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1663368003854,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "cda01022",
    "outputId": "d0f4a1f0-efb8-4a50-e74d-3af2638c1a98"
   },
   "outputs": [],
   "source": [
    "# Display first 10 rows.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7IVcXx_3fFq"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `head()` function from the `pandas` library can be helpful here.\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XnaSp-1bco5"
   },
   "source": [
    "Now, display the variable names and their data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1663368003855,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "yjTctqf_cZZk",
    "outputId": "43f19198-4e92-40d0-b3ad-651d9c6d82ff"
   },
   "outputs": [],
   "source": [
    "# Display variable names and types.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyjsCPSFdWSi"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "DataFrames have an attribute that outputs variable names and data types in one result.\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZWcyh0ia_mn"
   },
   "source": [
    "**Question:** What do you observe about the differences in data types among the variables included in the data?\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDHCzUpwBqTD"
   },
   "source": [
    "Next, to understand the size of the dataset, identify the number of rows and the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1663368003856,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "p-s0dOOgBr-1",
    "outputId": "6f032712-04eb-43ca-b7d1-47e863d2766e"
   },
   "outputs": [],
   "source": [
    "# Identify the number of rows and the number of columns.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7phg3U50drdh"
   },
   "source": [
    "<details>\n",
    "  <summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "There is a method in the `pandas` library that outputs the number of rows and the number of columns in one result.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ada5a098-e0d2-4a59-9ac5-132d8ea1eb3c",
    "tags": []
   },
   "source": [
    "Now, check for missing values in the rows of the data. Start with .isna() to get Booleans indicating whether each value in the data is missing. Then, use .any(axis=1) to get Booleans indicating whether there are any missing values along the columns in each row. Finally, use .sum() to get the number of rows that contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1663368004257,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "db9be321-d578-4252-833c-a2dfd0e2e937",
    "outputId": "87ff2ba9-3e52-41bc-bffe-40181eedd382"
   },
   "outputs": [],
   "source": [
    "# Get Booleans to find missing values in data.\n",
    "# Get Booleans to find missing values along columns.\n",
    "# Get the number of rows that contain missing values.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data.isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74e5308a-7607-4277-a508-d0efa10d9116"
   },
   "source": [
    "**Question:** How many rows of data are missing values?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb005a73-4621-45b9-8114-30472ce20327"
   },
   "source": [
    "Drop the rows with missing values. This is an important step in data cleaning, as it makes the data more useful for analysis and regression. Then, save the resulting pandas DataFrame in a variable named `air_data_subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cee438e-8b1f-4855-855e-3723d1958b69"
   },
   "outputs": [],
   "source": [
    "# Drop missing values.\n",
    "# Save the DataFrame in variable `air_data_subset`.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data_subset = air_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AHDkLF5pnao"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `dropna()` function is helpful here.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The axis parameter passed in to this function should be set to 0 (if you want to drop rows containing missing values) or 1 (if you want to drop columns containing missing values).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0021b18e-4c93-4628-8d0d-2c55a98cc691"
   },
   "source": [
    "Next, display the first 10 rows to examine the data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1663368004259,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "ad471526-eb38-4cc3-afa7-f9542439ea35",
    "outputId": "f10297f7-f4d6-415b-d487-de4a1a9e6ef3"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data_subset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c74ad00-3eaf-4868-b3a9-3aa87a5bc0d3",
    "tags": []
   },
   "source": [
    "Confirm that it does not contain any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1663368004260,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "f22e303c-2c42-4227-9083-447839e2b300",
    "outputId": "9995365d-6956-4bce-8dcb-ed400478d798"
   },
   "outputs": [],
   "source": [
    "# Count of missing values.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0Y9g4C17al8"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can use the `.ina().sum()` to get the number of missing values for each variable.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23bbe395"
   },
   "source": [
    "Next, convert the categorical features to indicator (one-hot encoded) features. \n",
    "\n",
    "**Note:** The `drop_first` argument can be kept as default (`False`) during one-hot encoding for random forest models, so it does not need to be specified. Also, the target variable, `satisfaction`, does not need to be encoded and will be extracted in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03d00d56"
   },
   "outputs": [],
   "source": [
    "# Convert categorical features to one-hot encoded features.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data_subset_dummies = pd.get_dummies(air_data_subset, \n",
    "                                         columns=['Customer Type','Type of Travel','Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9d3a8d5"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can use the `pd.get_dummies()` function to convert categorical variables to one-hot encoded variables.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fY6JM-6zfNLK"
   },
   "source": [
    "**Question:** Why is it necessary to convert categorical data into dummy variables?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfe87acc"
   },
   "source": [
    "Next, display the first 10 rows to review the `air_data_subset_dummies`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1663368004262,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "139cb903",
    "outputId": "8fde7c8c-9e24-4b2d-d39f-810fafbfdd2b"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data_subset_dummies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXzLIPbYYvud"
   },
   "source": [
    "Then, check the variables of air_data_subset_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1663368004262,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "X1V76nRmZoWN",
    "outputId": "9d0a4a46-8f29-43bd-8572-fd9295343370"
   },
   "outputs": [],
   "source": [
    "# Display variables.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "air_data_subset_dummies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJkFXh96gIA2"
   },
   "source": [
    "**Question:** What changes do you observe after converting the string data to dummy variables?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b7f8803-44ee-47cf-b97a-efaf5c0fdd59",
    "tags": []
   },
   "source": [
    "## **Step 3: Model building** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sf5gGBFySHv"
   },
   "source": [
    "The first step to building your model is separating the labels (y) from the features (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80535d2f-8b1a-4715-b07a-f3734d8cc4c5"
   },
   "outputs": [],
   "source": [
    "# Separate the dataset into labels (y) and features (X).\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "y = air_data_subset_dummies[\"satisfaction\"]\n",
    "X = air_data_subset_dummies.drop(\"satisfaction\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18fn6lxL8O8Q"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Save the labels (the values in the `satisfaction` column) as `y`.\n",
    "\n",
    "Save the features as `X`. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "To obtain the features, drop the `satisfaction` column from the DataFrame.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49a6c7ae"
   },
   "source": [
    "Once separated, split the data into train, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0de77cb8"
   },
   "outputs": [],
   "source": [
    "# Separate into train, validate, test sets.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16c78c74"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `train_test_split()` function twice to create train/validate/test sets, passing in `random_state` for reproducible results. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Split `X`, `y` to get `X_train`, `X_test`, `y_train`, `y_test`. Set the `test_size` argument to the proportion of data points you want to select for testing. \n",
    "\n",
    "Split `X_train`, `y_train` to get `X_tr`, `X_val`, `y_tr`, `y_val`. Set the `test_size` argument to the proportion of data points you want to select for validation. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59bbd17e-84e5-463c-8806-f2b5286f9ac8",
    "tags": []
   },
   "source": [
    "### Tune the model\n",
    "\n",
    "Now, fit and tune a random forest model with separate validation set. Begin by determining a set of hyperparameters for tuning the model using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bfdf346"
   },
   "outputs": [],
   "source": [
    "# Determine set of hyperparameters.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "cv_params = {'n_estimators' : [50,100], \n",
    "              'max_depth' : [10,50],        \n",
    "              'min_samples_leaf' : [0.5,1], \n",
    "              'min_samples_split' : [0.001, 0.01],\n",
    "              'max_features' : [\"sqrt\"], \n",
    "              'max_samples' : [.5,.9]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMdizCS0rZB4"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Create a dictionary `cv_params` that maps each hyperparameter name to a list of values. The GridSearch you conduct will set the hyperparameter to each possible value, as specified, and determine which value is optimal.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Swkbtmw7tMMv"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The main hyperparameters here include `'n_estimators', 'max_depth', 'min_samples_leaf', 'min_samples_split', 'max_features', and 'max_samples'`. These will be the keys in the dictionary `cv_params`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a list of split indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a58b4d77-6023-428d-89aa-4d2ac52003dc"
   },
   "outputs": [],
   "source": [
    "# Create list of split indices.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "split_index = [0 if x in X_val.index else -1 for x in X_train.index]\n",
    "custom_split = PredefinedSplit(split_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USX90GwZt3xU"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use list comprehension, iterating over the indices of `X_train`. The list can consists of 0s to indicate data points that should be treated as validation data and -1s to indicate data points that should be treated as training data.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Use `PredfinedSplit()`, passing in `split_index`, saving the output as `custom_split`. This will serve as a custom split that will identify which data points from the train set should be treated as validation data during GridSearch.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0qvZjujbTKL"
   },
   "outputs": [],
   "source": [
    "# Instantiate model.\n",
    "\n",
    "### YOUR CODE HERE ### \n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voetM7-QwI5w"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use `RandomForestClassifier()`, specifying the `random_state` argument for reproducible results. This will help you instantiate a random forest model, `rf`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use GridSearchCV to search over the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "228e65c3"
   },
   "outputs": [],
   "source": [
    "# Search over specified parameters.\n",
    "\n",
    "### YOUR CODE HERE ### \n",
    "\n",
    "rf_val = GridSearchCV(rf, cv_params, cv=custom_split, refit='f1', n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bppjmuqzwZf3"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use `GridSearchCV()`, passing in `rf` and `cv_params` and specifying `cv` as `custom_split`. Additional arguments that you can specify include: `refit='f1', n_jobs = -1, verbose = 1`. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82938,
     "status": "ok",
     "timestamp": 1663368087480,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "gw_woSKtfsAk",
    "outputId": "4928a458-1ff2-476e-9a0b-df5504b4ebe3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "rf_val.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUYHWoZsyJs0"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `fit()` method to train the GridSearchCV model on `X_train` and `y_train`. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Add the magic function `%%time` to keep track of the amount of time it takes to fit the model and display this information once execution has completed. Remember that this code must be the first line in the cell.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, obtain the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1663368087481,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "c76a0bd9",
    "outputId": "e5def2af-f1b9-4d49-9076-35c18e4bdb38"
   },
   "outputs": [],
   "source": [
    "# Obtain optimal parameters.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "rf_val.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "604a475e"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `best_params_` attribute to obtain the optimal values for the hyperparameters from the GridSearchCV model.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70fc3ec6-a89a-4b25-a574-29f9d4325694"
   },
   "source": [
    "## **Step 4: Results and evaluation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXqywQtvyrS1"
   },
   "source": [
    "Use the selected model to predict on your test data. Use the optimal parameters found via GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6b8aa2d-984f-467a-b52a-e7f21d603a8c"
   },
   "outputs": [],
   "source": [
    "# Use optimal parameters on GridSearchCV.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "rf_opt = RandomForestClassifier(n_estimators = 50, max_depth = 50, \n",
    "                                min_samples_leaf = 1, min_samples_split = 0.001,\n",
    "                                max_features=\"sqrt\", max_samples = 0.9, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu3sgtdRzmmJ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use `RandomForestClassifier()`, specifying the `random_state` argument for reproducible results and passing in the optimal hyperparameters found in the previous step. To distinguish this from the previous random forest model, consider naming this variable `rf_opt`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, fit the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6112,
     "status": "ok",
     "timestamp": 1663368093585,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "iJ7MkQ3hjh3u",
    "outputId": "d53a73a4-b993-4d34-93b9-9364aae56c20"
   },
   "outputs": [],
   "source": [
    "# Fit the optimal model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "rf_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAKs_7Ms0HAO"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Use the `fit()` method to train `rf_opt` on `X_train` and `y_train`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predict on the test set using the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cc40ec1-5fa4-4803-9021-abea9699a804"
   },
   "outputs": [],
   "source": [
    "# Predict on test set.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "y_pred = rf_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4df36d33"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `predict()` function to make predictions on `X_test` using `rf_opt`. Save the predictions now (for example, as `y_pred`), to use them later for comparing to the true labels. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "153a8200"
   },
   "source": [
    "### Obtain performance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cea208e9"
   },
   "source": [
    "First, get your precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1663368094079,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "6913aa4b",
    "outputId": "779df510-8f17-4e92-85c1-e722b4154e51"
   },
   "outputs": [],
   "source": [
    "# Get precision score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "pc_test = precision_score(y_test, y_pred, pos_label = \"satisfied\")\n",
    "print(\"The precision score is {pc:.3f}\".format(pc = pc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVtVtsLV0ddI"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `precision_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66dda49b"
   },
   "source": [
    "Then, collect the recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1663368094731,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "dd971df6",
    "outputId": "62641fc3-e6f1-42e5-efdf-398e9ee24e22"
   },
   "outputs": [],
   "source": [
    "# Get recall score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "rc_test = recall_score(y_test, y_pred, pos_label = \"satisfied\")\n",
    "print(\"The recall score is {rc:.3f}\".format(rc = rc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XUaS34s1yH_"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `recall_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea594a68"
   },
   "source": [
    "Next, obtain your accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1663368094732,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "011b8b71",
    "outputId": "eabca891-7da1-4da6-8109-9c778297436f"
   },
   "outputs": [],
   "source": [
    "# Get accuracy score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "ac_test = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy score is {ac:.3f}\".format(ac = ac_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QProyXMS10zG"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `accuracy_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "871ea5cb"
   },
   "source": [
    "Finally, collect your F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1663368095515,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "490fcb3e",
    "outputId": "a69a2aec-0b53-4a59-ee5b-650149dce00d"
   },
   "outputs": [],
   "source": [
    "# Get F1 score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "f1_test = f1_score(y_test, y_pred, pos_label = \"satisfied\")\n",
    "print(\"The F1 score is {f1:.3f}\".format(f1 = f1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtBQWSVs13dT"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "You can call the `f1_score()` function from `sklearn.metrics`, passing in `y_test` and `y_pred` and specifying the `pos_label` argument as `\"satisfied\"`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1edc4c95-1cf4-4e05-b2a2-dc18cadb3d63"
   },
   "source": [
    "**Question:** How is the F1-score calculated?**\n",
    "\n",
    "F1 scores are calculated using the following formula: \n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfkbwjlvcX3k"
   },
   "source": [
    "**Question:** What are the pros and cons of performing the model selection using test data instead of a separate validation dataset?\n",
    "\n",
    "Pros: <br />\n",
    "*  The coding workload is reduced.\n",
    "*  The scripts for data splitting are shorter.\n",
    "*  It's only  necessary to evaluate test dataset performance once, instead of two evaluations (validate and test).\n",
    "\n",
    "Cons: <br />\n",
    "* If a model is evaluated using samples that were also used to build or fine-tune that model, it likely will provide a biased evaluation.\n",
    "* A potential overfitting issue could happen when fitting the model's scores on the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "510b2158-2813-4600-868e-a909595a2366"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Now that you have results, evaluate the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57771b26"
   },
   "source": [
    "**Question:** What are the four basic parameters for evaluating the performance of a classification model?\n",
    "\n",
    "1. True positives (TP): These are correctly predicted positive values, which means the value of actual and predicted classes are positive. \n",
    "\n",
    "2. True negatives (TN): These are correctly predicted negative values, which means the value of the actual and predicted classes are negative.\n",
    "\n",
    "3. False positives (FP): This occurs when the value of the actual class is negative and the value of the predicted class is positive.\n",
    "\n",
    "4. False negatives (FN): This occurs when the value of the actual class is positive and the value of the predicted class in negative. \n",
    "\n",
    "**Reminder:** When fitting and tuning classification modeld, data professioals aim to minimize false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LojJPkIrjNbJ"
   },
   "source": [
    "**Question:**  What do the four scores demonstrate about your model, and how do you calculate them?\n",
    "\n",
    "- Accuracy (TP+TN/TP+FP+FN+TN): The ratio of correctly predicted observations to total observations. \n",
    " \n",
    "- Precision (TP/TP+FP): The ratio of correctly predicted positive observations to total predicted positive observations. \n",
    "\n",
    "- Recall (Sensitivity, TP/TP+FN): The ratio of correctly predicted positive observations to all observations in actual class.\n",
    "\n",
    "- F1 score: The harmonic average of precision and recall, which takes into account both false positives and false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgFj_nMabpsf"
   },
   "source": [
    "Calculate the scores: precision score, recall score, accuracy score, F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1663368095518,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "RUT99rnqOds3",
    "outputId": "0e65d9bd-6617-42b9-fd35-14974bd3b4d5"
   },
   "outputs": [],
   "source": [
    "# Precision score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(\"\\nThe precision score is: {pc:.3f}\".format(pc = pc_test), \"for the test set,\", \"\\nwhich means of all positive predictions,\", \"{pc_pct:.1f}% prediction are true positive.\".format(pc_pct = pc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1663368095518,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "GTiaHUVvTiUN",
    "outputId": "97e3637d-ed56-4ef1-ea8b-4dd5902ee6ee"
   },
   "outputs": [],
   "source": [
    "# Recall score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(\"\\nThe recall score is: {rc:.3f}\".format(rc = rc_test), \"for the test set,\", \"\\nwhich means of which means of all real positive cases in test set,\", \"{rc_pct:.1f}% are  predicted positive.\".format(rc_pct = rc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1663368095886,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "VrYHruUdV1Os",
    "outputId": "ec36d8b8-c284-4e50-fba8-8e6de185383d"
   },
   "outputs": [],
   "source": [
    "# Accuracy score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(\"\\nThe accuracy score is: {ac:.3f}\".format(ac = ac_test), \"for the test set,\", \"\\nwhich means of all cases in test set,\", \"{ac_pct:.1f}% are predicted true positive or true negative.\".format(ac_pct = ac_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1663368095888,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "pKGc64U2YbL1",
    "outputId": "86d8c589-efa6-44dd-b925-1a891288d5a3"
   },
   "outputs": [],
   "source": [
    "# F1 score on test data set.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(\"\\nThe F1 score is: {f1:.3f}\".format(f1 = f1_test), \"for the test set,\", \"\\nwhich means the test set's harmonic mean is {f1_pct:.1f}%.\".format(f1_pct = f1_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does this model perform based on the four scores?\n",
    "\n",
    "The model performs well according to all 4 performance metrics. The model's precision score is slightly better than the 3 other metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaKUSbqDW28K"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Finally, create a table of results that you can use to evaluate the performace of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1663368095889,
     "user": {
      "displayName": "Lavanya Vijayan",
      "userId": "01043085078394539645"
     },
     "user_tz": 420
    },
    "id": "6L7AgdeldsKZ",
    "outputId": "ce6c30b7-29d9-44c0-e484-0ab64aeeda6a"
   },
   "outputs": [],
   "source": [
    "# Create table of results.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table = table.append({'Model': \"Tuned Decision Tree\",\n",
    "                        'F1':  0.945422,\n",
    "                        'Recall': 0.935863,\n",
    "                        'Precision': 0.955197,\n",
    "                        'Accuracy': 0.940864\n",
    "                      },\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "\n",
    "table = table.append({'Model': \"Tuned Random Forest\",\n",
    "                        'F1':  f1_test,\n",
    "                        'Recall': rc_test,\n",
    "                        'Precision': pc_test,\n",
    "                        'Accuracy': ac_test\n",
    "                      },\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqu9L0ip328H"
   },
   "source": [
    "\n",
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Build a table to compare the performance of the models. Create a DataFrame and use the `append()` function to add the results of each model as a new row.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trUO9XEHbXG6"
   },
   "source": [
    "**Question:** How does the random forest model compare to the decision tree model you built in the previous lab?\n",
    "\n",
    "The tuned random forest has higher scores overall, so it is the better model. Particularly, it shows a better F1 score than the decision tree model, which indicates that the random forest model may do better at classification when taking into account false positives and false negatives. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okMTunOhpotF"
   },
   "source": [
    "## **Considerations**\n",
    "\n",
    "\n",
    "**What are the key takeaways from this lab?**\n",
    "- Data exploring, cleaning, and encoding are necessary for model building.\n",
    "- A separate validation set is typically used for tuning a model, rather than using the test set. This also helps avoid the evaluation becoming biased.\n",
    "-  F1 scores are usually more useful than accuracy scores. If the cost of false positives and false negatives are very different, it’s better to use the F1 score and combine the information from precision and recall. \n",
    "* The random forest model yields a more effective performance than a decision tree model. \n",
    "\n",
    "**What summary would you provide to stakeholders?**\n",
    "* The random forest model predicted satisfaction with more than 94.2% accuracy. The precision is over 95% and the recall is approximately 94.5%. \n",
    "* The random forest model outperformed the tuned decision tree with the best hyperparameters in most of the four scores. This indicates that the random forest model may perform better.\n",
    "* Because stakeholders were interested in learning about the factors that are most important to customer satisfaction, this would be shared based on the tuned random forest. \n",
    "* In addition, you would provide details about the precision, recall, accuracy, and F1 scores to support your findings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb58bfc4"
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c2abcc0"
   },
   "source": [
    "[Accuracy, Precision, Recall & F1 Score: Interpretation of Performance Measures, Renuka Joshi](https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/)\n",
    "\n",
    "[What is the Difference Between Test and Validation Datasets?,  Jason Brownlee](https://machinelearningmastery.com/difference-test-validation-datasets/)\n",
    "\n",
    "[Decision Trees and Random Forests Neil Liberman](https://towardsdatascience.com/decision-trees-and-random-forests-df0c3123f991)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1ajeXfekjHYYlATQqDdzWb2bjoSQPy9e5",
     "timestamp": 1661470003810
    },
    {
     "file_id": "1sKzoVdsFNq2nBg0uus6LyTzuD2Ktou4t",
     "timestamp": 1661452831142
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
